dataset,version,metric,mode,qwen2-7b-hf
commonsense_qa,c946f2,accuracy,gen,20.31
openai_humaneval,8e312c,humaneval_pass@1,gen,0.00
gsm8k,1d7fe4,accuracy,gen,1.59
chid-dev,211ee7,accuracy,gen,12.87
chid-test,211ee7,accuracy,gen,12.54
truthful_qa,5ddc62,truth,gen,0.69
bbh-temporal_sequences,e43931,score,gen,25.60
bbh-disambiguation_qa,d52c61,score,gen,40.40
bbh-date_understanding,a8000b,score,gen,20.00
bbh-tracking_shuffled_objects_three_objects,7964c0,score,gen,28.30
bbh-penguins_in_a_table,fceb27,score,gen,14.38
bbh-geometric_shapes,503c8f,score,gen,0.00
bbh-snarks,42d6ca,score,gen,41.57
bbh-ruin_names,408de8,score,gen,24.4
bbh-tracking_shuffled_objects_seven_objects,7964c0,score,gen,13.20
bbh-tracking_shuffled_objects_five_objects,7964c0,score,gen,18.40
bbh-logical_deduction_three_objects,45ebc5,score,gen,30.0
bbh-hyperbaton,5e5016,score,gen,48.40
bbh-logical_deduction_five_objects,45ebc5,score,gen,16.00
bbh-logical_deduction_seven_objects,45ebc5,score,gen,5.60
bbh-movie_recommendation,cc2fde,score,gen,16.00
bbh-salient_translation_error_detection,5b5f35,score,gen,10.60
bbh-reasoning_about_colored_objects,1cb761,score,gen,6.20
bbh-multistep_arithmetic_two,30f91e,score,gen,0.00
bbh-navigate,1576d9,score,gen,20.10
bbh-dyck_languages,805bea,score,gen,0.00
bbh-word_sorting,9a3f78,score,gen,0.00
bbh-sports_understanding,d3fa77,score,gen,48.00
bbh-boolean_expressions,612c92,score,gen,0.00
bbh-object_counting,781e5c,score,gen,9.30
bbh-formal_fallacies,eada96,score,gen,0.00
bbh-causal_judgement,89eaa4,score,gen,3.60
bbh-web_of_lies,0c0441,score,gen,4.50
bbh,-,naive_average,gen,16.46

Average memory used during inference: 9082.4931640625 MB
Average inference time: 0.0724 seconds
Throughput: 13.81 inferences/second

